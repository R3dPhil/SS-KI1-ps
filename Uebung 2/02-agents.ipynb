{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligente Agenten\n",
    "Beantworten Sie die folgenden Fragen!\n",
    "## Der Turing-Test\n",
    "1. Wie funktioniert der Turing-Test?\n",
    "2. Was braucht eine Maschine um den Test zu bestehen?\n",
    "3. Was ist der totale Turing-Test?\n",
    "4. Was braucht eine Maschine um den totalen Turing-Test zu bestehen?\n",
    "5. Welche Probleme existieren beim Turing-Test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenten\n",
    "1. Was ist ein Agent? Aus welchen Bestandteilen besteht ein Agent?\n",
    "2. Welche Arten von Agenten kennen Sie? Wie zeichnen Sich die einzelnen Agententypen aus?\n",
    "3. Durch welche Eigenschaften zeichnet sich eine Umgebung aus in der sich ein Agent bewegt?:<br/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Der Staubsauger als Agent\n",
    "Wir werden heute einen Staubsauger-Agenten und die dazugehörige Umgebung bzw. \"Welt\" programmieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst definieren wir uns eine Klasse \"Environment\". Diese Klasse repräsentiert unsere Welt in der sich der Agent bewegen soll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InvalidActionError(Exception):\n",
    "    \"\"\"Wird ausgelöst, wenn eine ungültige Aktion ausgeführt werden soll.\"\"\"\n",
    "    pass\n",
    "\n",
    "class Environment:\n",
    "    \"\"\"Class representing an Environment. Other environment classes can\n",
    "    inherit from this. They typically need to implement:\n",
    "        percept:           Define the percept that an agent sees.\n",
    "        execute_action:    Define the effects of executing an action.\n",
    "                           Also update the agent.performance slot.\n",
    "    The environment keeps a dict of .loc_status which includes locations and their respective status. \n",
    "    There is also a list of .agents.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.loc_status = {(0, 0): random.choice(['Clean', 'Dirty']),\n",
    "                          (0, 1): random.choice(['Clean', 'Dirty']),\n",
    "                          (1, 0): random.choice(['Clean', 'Dirty']),\n",
    "                          (1, 1): random.choice(['Clean', 'Dirty'])}\n",
    "        self.agents = []\n",
    "        self.time = 0\n",
    "\n",
    "\n",
    "    def percept(self, agent):\n",
    "        \"\"\"Returns the agent's location, and the location status (Dirty/Clean).\"\"\"\n",
    "        return (agent.location, self.loc_status[agent.location])\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        \"\"\"Change agent's location and/or location's status\"\"\"\n",
    "        former_location = agent.location\n",
    "        if action == 'move_left' and agent.location[1] > 0:\n",
    "            agent.location = (agent.location[0], agent.location[1]-1)\n",
    "            print(f\"Moving left: {former_location} -> {agent.location}\")\n",
    "            print(\"World state: \", self.loc_status)\n",
    "        elif action == 'move_right' and agent.location[1] < 1:\n",
    "            agent.location = (agent.location[0], agent.location[1]+1)\n",
    "            print(f\"Moving right: {former_location} -> {agent.location}\")\n",
    "            print(\"World state: \", self.loc_status)\n",
    "        elif action == 'move_down' and agent.location[0] < 1:\n",
    "            agent.location = (agent.location[0]+1, agent.location[1])\n",
    "            print(f\"Moving down: {former_location} -> {agent.location}\")\n",
    "            print(\"World state: \", self.loc_status)\n",
    "        elif action == 'move_up' and agent.location[0] > 0:\n",
    "            agent.location = (agent.location[0]-1, agent.location[1])\n",
    "            print(f\"Moving up: {former_location} -> {agent.location}\")\n",
    "            print(\"World state: \", self.loc_status)\n",
    "        elif action == 'clean':\n",
    "            self.loc_status[agent.location] = 'Clean'\n",
    "            print(\"Cleaning: \", agent.location)\n",
    "            print(\"World state: \", self.loc_status)\n",
    "        elif action == 'do_nothing':\n",
    "            print(\"Doing nothing at location:\", agent.location)\n",
    "            print(\"World state: \", self.loc_status)\n",
    "        else:\n",
    "            error_message = f\"Ungültige Aktion '{action}' vom Agenten an Position {former_location}!\"\n",
    "            print(error_message)\n",
    "            raise InvalidActionError(error_message)\n",
    "            \n",
    "    \n",
    "\n",
    "    def default_location(self, thing):\n",
    "        \"\"\"Agents start in either location at random.\"\"\"\n",
    "        return random.choice([(0,0), (0,1), (1,0), (1,1)])\n",
    "\n",
    "    def exogenous_change(self):\n",
    "        \"\"\"If there is spontaneous change in the world, override this.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Run the environment for one time step. If the\n",
    "        actions and exogenous changes are independent, this method will\n",
    "        do. If there are interactions between them, you'll need to\n",
    "        override this method.\"\"\"\n",
    "        actions = []\n",
    "        \n",
    "        for agent in self.agents:\n",
    "            actions.append(agent.program(self.percept(agent)))\n",
    "        for (agent, action) in zip(self.agents, actions):\n",
    "            self.execute_action(agent, action)\n",
    "        self.exogenous_change()\n",
    "\n",
    "    def run(self, steps=10):\n",
    "        \"\"\"Run the Environment for given number of time steps.\"\"\"\n",
    "        print(\"Initial world state: \", self.loc_status)\n",
    "        for step in range(steps):\n",
    "            self.time += 1\n",
    "            self.step()\n",
    "            if all(value == \"Clean\" for value in self.loc_status.values()):\n",
    "                break\n",
    "\n",
    "    def add_agent(self, agent, location=None):\n",
    "        \"\"\"Add a thing to the environment, setting its location. For\n",
    "        convenience, if thing is an agent program we make a new agent\n",
    "        for it. (Shouldn't need to override this.)\"\"\"\n",
    "        if agent in self.agents:\n",
    "            print(\"Can't add the same agent twice\")\n",
    "        else:\n",
    "            agent.location = location if location is not None else self.default_location(agent)\n",
    "            self.agents.append(agent)\n",
    "\n",
    "    def delete_agent(self, agent):\n",
    "        \"\"\"Remove agent from the environment.\"\"\"\n",
    "        try:\n",
    "            self.agents.remove(agent)\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            print(\"  in Environment delete_agent\")\n",
    "            print(\"  Agent to be removed: {} at {}\".format(agent, agent.location))\n",
    "            print(\"  from list: {}\".format([(agent, agent.location) for agent in self.agents]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dann benötigen wir noch eine Klasse für unsere Agenten. Da wir im Laufe der Übung unterschiedliche Agenten implementieren möchten verwenden wir zunächst eine sogenannte \"abstrakte\" Klasse `TraceAgent`, von der unsere späteren konkreten Agent-Klassen erben können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TraceAgent:\n",
    "    \"\"\"An abstract class of an agent. Concrete agent classes wil inherit from this class and have to provide (at least) a program function.\n",
    "    Optionally you can also provide an __init__ function if the agent should have internal states.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loc_status = None\n",
    "        self.location = None\n",
    "        \n",
    "    def programm(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier sehen wir nun eine mögliche Implementierung einer `SimpleAgent`-Klasse. Dabei erbt diese Klasse alle Methoden und Attribute von der abstrakten Klasse `TraceAgent` und überschreibt diese gegebenenfalls mit ihrer eigenen Logik. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleAgent(TraceAgent):\n",
    "    def program(self, perception):\n",
    "        self.location, loc_status = perception\n",
    "        if loc_status == \"Clean\":\n",
    "            action = \"do_nothing\"\n",
    "        else:\n",
    "            action = \"clean\"\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun könnne wir uns mit folgender Zelle eine neue Welt erstellen und unseren `SimpleAgent`zu dieser Welt hinzufügen. Anschließend Simulieren wir 10 Zeitschritte in dieser Welt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial world state:  {(0, 0): 'Clean', (0, 1): 'Clean', (1, 0): 'Clean', (1, 1): 'Dirty'}\n",
      "Cleaning:  (1, 1)\n",
      "World state:  {(0, 0): 'Clean', (0, 1): 'Clean', (1, 0): 'Clean', (1, 1): 'Clean'}\n"
     ]
    }
   ],
   "source": [
    "e = Environment()\n",
    "e.add_agent(SimpleAgent())\n",
    "e.run(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1\n",
    "Implementieren Sie die Klasse ReflexAgent als einfachen Reflex-Agenten. Das Verhalten können sie dabei selbst festlegen. Der Agent soll dabei in unserer Welt \"Environment\" funktionieren. Beachten Sie diesen Umstand bei der Festlegung möglicher Aktionen, die der Agent in der genannten Welt ausführen soll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial world state:  {(0, 0): 'Clean', (0, 1): 'Dirty', (1, 0): 'Dirty', (1, 1): 'Clean'}\n",
      "Moving up: (1, 1) -> (0, 1)\n",
      "World state:  {(0, 0): 'Clean', (0, 1): 'Dirty', (1, 0): 'Dirty', (1, 1): 'Clean'}\n",
      "Cleaning:  (0, 1)\n",
      "World state:  {(0, 0): 'Clean', (0, 1): 'Clean', (1, 0): 'Dirty', (1, 1): 'Clean'}\n",
      "Moving down: (0, 1) -> (1, 1)\n",
      "World state:  {(0, 0): 'Clean', (0, 1): 'Clean', (1, 0): 'Dirty', (1, 1): 'Clean'}\n",
      "Ungültige Aktion 'move_right' vom Agenten an Position (1, 1)!\n"
     ]
    },
    {
     "ename": "InvalidActionError",
     "evalue": "Ungültige Aktion 'move_right' vom Agenten an Position (1, 1)!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidActionError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m a1 \u001b[38;5;241m=\u001b[39m ReflexAgent()\n\u001b[0;32m     11\u001b[0m e1\u001b[38;5;241m.\u001b[39madd_agent(a1)\n\u001b[1;32m---> 12\u001b[0m \u001b[43me1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[43], line 88\u001b[0m, in \u001b[0;36mEnvironment.run\u001b[1;34m(self, steps)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(value \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClean\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc_status\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m     90\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[43], line 80\u001b[0m, in \u001b[0;36mEnvironment.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m     actions\u001b[38;5;241m.\u001b[39mappend(agent\u001b[38;5;241m.\u001b[39mprogram(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpercept(agent)))\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (agent, action) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents, actions):\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexogenous_change()\n",
      "Cell \u001b[1;32mIn[43], line 58\u001b[0m, in \u001b[0;36mEnvironment.execute_action\u001b[1;34m(self, agent, action)\u001b[0m\n\u001b[0;32m     56\u001b[0m error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUngültige Aktion \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m vom Agenten an Position \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformer_location\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(error_message)\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidActionError(error_message)\n",
      "\u001b[1;31mInvalidActionError\u001b[0m: Ungültige Aktion 'move_right' vom Agenten an Position (1, 1)!"
     ]
    }
   ],
   "source": [
    "class ReflexAgent(TraceAgent):\n",
    "    def program(self, perception):\n",
    "        self.location, loc_status = perception\n",
    "        if loc_status == \"Clean\":\n",
    "            action = random.choice([\"move_up\", \"move_down\", \"move_left\", \"move_right\"])\n",
    "        else:\n",
    "            action = \"clean\"\n",
    "        return action\n",
    "e1 = Environment()\n",
    "a1 = ReflexAgent()\n",
    "e1.add_agent(a1)\n",
    "e1.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2\n",
    "Implementieren Sie die Klasse \"ModelBasedAgent\" als modellbasierten Agenten. Auch dieser Agent soll in der \"Environment\" funktionieren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial world state:  {(0, 0): 'Dirty', (0, 1): 'Clean', (1, 0): 'Clean', (1, 1): 'Clean'}\n",
      "Model state:  {(0, 0): None, (0, 1): None, (1, 0): None, (1, 1): None}\n",
      "(1, 1)  is clean\n",
      "Moving up: (1, 1) -> (0, 1)\n",
      "World state:  {(0, 0): 'Dirty', (0, 1): 'Clean', (1, 0): 'Clean', (1, 1): 'Clean'}\n",
      "Model state:  {(0, 0): None, (0, 1): None, (1, 0): None, (1, 1): None}\n",
      "(0, 1)  is clean\n",
      "Cannot move there.\n",
      "Model state:  {(0, 0): None, (0, 1): None, (1, 0): None, (1, 1): None}\n",
      "(0, 1)  is clean\n",
      "Cannot move there.\n",
      "Model state:  {(0, 0): None, (0, 1): None, (1, 0): None, (1, 1): None}\n",
      "(0, 1)  is clean\n",
      "Cannot move there.\n",
      "Model state:  {(0, 0): None, (0, 1): None, (1, 0): None, (1, 1): None}\n",
      "(0, 1)  is clean\n",
      "Cannot move there.\n",
      "Model state:  {(0, 0): None, (0, 1): None, (1, 0): None, (1, 1): None}\n",
      "(0, 1)  is clean\n",
      "Cannot move there.\n",
      "Model state:  {(0, 0): None, (0, 1): None, (1, 0): None, (1, 1): None}\n",
      "(0, 1)  is clean\n",
      "Cannot move there.\n",
      "Model state:  {(0, 0): None, (0, 1): None, (1, 0): None, (1, 1): None}\n",
      "(0, 1)  is clean\n",
      "Cannot move there.\n",
      "Model state:  {(0, 0): None, (0, 1): None, (1, 0): None, (1, 1): None}\n",
      "(0, 1)  is clean\n",
      "Cannot move there.\n",
      "Model state:  {(0, 0): None, (0, 1): None, (1, 0): None, (1, 1): None}\n",
      "(0, 1)  is clean\n",
      "Cannot move there.\n"
     ]
    }
   ],
   "source": [
    "class ModelBasedAgent(TraceAgent):\n",
    "    def __init__(self):\n",
    "        self.loc_status = {(0, 0): None, (0, 1): None, (1, 0): None, (1, 1): None} # world model\n",
    "        self.location = None\n",
    "    def program(self, perception):\n",
    "        location, loc_status = perception\n",
    "        self.location = location\n",
    "        print(\"Model state: \", self.loc_status)\n",
    "        if loc_status == \"Dirty\":\n",
    "             return \"clean\"\n",
    "        else:\n",
    "            print(self.location,\" is clean\")\n",
    "            (x,y)=self.location\n",
    "            for (x1,y1) in [(0,0),(1,0),(0,1),(1,1)]:\n",
    "                if self.loc_status[(x1,y1)] == \"Dirty\" or self.loc_status[(x1,y1)] == None:\n",
    "                    if x==x1: \n",
    "                        if y==1:\n",
    "                            return \"move_up\"\n",
    "                        else:                        \n",
    "                            return \"move_down\"\n",
    "                    if y==y1: \n",
    "                        if x==1:\n",
    "                            return \"move_left\"\n",
    "                        else:\n",
    "                            return \"move_right\"\n",
    "            return \"do_nothing\"\n",
    "e2 = Environment()\n",
    "a2 = ModelBasedAgent()\n",
    "e2.add_agent(a2)\n",
    "e2.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 3\n",
    "Erweitern Sie die Implementierung der Environment, sodass es beliebig viele, auf einem 2D-Gitter angeordnete Positionen gibt. Erweitern Sie auch die Implementierung der beiden Agenten entsprechend, sodass diese sinnvoll in der neuen Umgebung agieren können"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ExtendedEnvironment(Environment):\n",
    "\n",
    "    \"\"\"This environment has nxn locations. Each can be Dirty\n",
    "    or Clean. The agent perceives its location and the location's\n",
    "    status. This serves as an example of how to implement a simple\n",
    "    Environment.\"\"\"\n",
    "\n",
    "    def __init__(self, grid_size: int):\n",
    "        super().__init__()\n",
    "        \"Implement me!\"\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        \"\"\"Change agent's location and/or location's status\"\"\"\n",
    "        \n",
    "        \"Implement me!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ExtendedModelBasedAgent(TraceAgent):\n",
    "    def __init__(self, loc_status):\n",
    "        self.loc_status = \"Implement me!\"\n",
    "        self.location = None\n",
    "    def program(self, perception):\n",
    "        location, loc_status = perception\n",
    "        self.location = location\n",
    "        self.loc_status[self.location] = loc_status\n",
    "        \n",
    "        return \"Implement my logic!\"\n",
    "\n",
    "e4 = Environment()\n",
    "a4 = ExtendedModelBasedAgent(e4.loc_status)\n",
    "e4.add_agent(a4)\n",
    "e4.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
